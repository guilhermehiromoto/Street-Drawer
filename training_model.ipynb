{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this project we are using a model-based methodology for Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A metrica que utilizaremos pra treinar o nosso modelo eh a Intersection-Over-Union\n",
    "\n",
    "Essa metrica consiste em calcular a area de sobreposição entre a segmentação prevista e a mascara dividido pela area de união entre a segmentação prevista e a mascara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "##Metrica\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "  \n",
    "    return iou\n",
    "##Loss Function\n",
    "#def iou_coef_loss(y_true, y_pred):\n",
    "#    return -iou_coef(y_true, y_pred)\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formando os arrays de imagens e mascaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.fsencode(\"./new_maps\")\n",
    "\n",
    "images = []\n",
    "titulos = []\n",
    "\n",
    "list_directory = os.listdir(directory.decode(\"utf-8\"))\n",
    "\n",
    "list_directory.sort()\n",
    "    \n",
    "for file in list_directory:\n",
    "    filename = os.fsdecode(file)\n",
    "    titulos.append(filename)\n",
    "    filename_path = directory.decode(\"utf-8\") + \"/\" + filename\n",
    "    img = imageio.imread(filename_path)\n",
    "    images.append(img)\n",
    "    \n",
    "directory = os.fsencode(\"./new_masks\")\n",
    "\n",
    "masks = []\n",
    "titulos = []\n",
    "\n",
    "list_directory = os.listdir(directory.decode(\"utf-8\"))\n",
    "\n",
    "list_directory.sort()\n",
    "    \n",
    "for file in list_directory:\n",
    "    filename = os.fsdecode(file)\n",
    "    titulos.append(filename)\n",
    "    filename_path = directory.decode(\"utf-8\") + \"/\" + filename\n",
    "    img = imageio.imread(filename_path)\n",
    "    masks.append(img)\n",
    "    \n",
    "masks = np.array(masks)\n",
    "images = np.array(images)\n",
    "\n",
    "masks = np.expand_dims(masks, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitando os dados entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, dropout = 0.1):\n",
    "\n",
    "    #Contração\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (input_img)\n",
    "    c1 = BatchNormalization() (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    c1 = BatchNormalization() (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = BatchNormalization() (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    c2 = BatchNormalization() (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = BatchNormalization() (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    c3 = BatchNormalization() (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = BatchNormalization() (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    c4 = BatchNormalization() (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = BatchNormalization() (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "    c5 = BatchNormalization() (c5)\n",
    "\n",
    "    #Expansão\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = BatchNormalization() (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "    c6 = BatchNormalization() (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = BatchNormalization() (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "    c7 = BatchNormalization() (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = BatchNormalization() (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "    c8 = BatchNormalization() (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = BatchNormalization() (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "    c9 = BatchNormalization() (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((256,256,3))\n",
    "model = get_unet(input_img, dropout=0.05)\n",
    "model.compile(\n",
    "        optimizer= Adam(),\n",
    "        #loss= \"binary_crossentropy\",\n",
    "        #metrics=[\"accuracy\"])\n",
    "        loss=soft_dice_loss,\n",
    "        metrics=[iou_coef])\n",
    "history = model.fit(train_images,\n",
    "                    train_masks/255,\n",
    "                    validation_split = 0.1,\n",
    "                    batch_size = 16,\n",
    "                    validation_data = (test_images,test_masks),\n",
    "                    epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(img):\n",
    "    m = img.min()\n",
    "    M = img.max()\n",
    "    print(m)\n",
    "    print(M)\n",
    "    return ((img-m)/(M-m))*1\n",
    "def threshold(img):\n",
    "    n = img.shape[0]\n",
    "    m = img.shape[1]\n",
    "    counter = 0\n",
    "    for x in range (n):\n",
    "        for y in range(m):\n",
    "            if img[x,y] < img.mean():\n",
    "                img[x,y] = 0\n",
    "            else:\n",
    "                img[x,y] = 255\n",
    "                counter+=1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "pred = (predictions > 0.5).astype(np.uint8)\n",
    "for i in range(0,6,3):\n",
    "    \n",
    "    j = random.randint(1,7)\n",
    "    f.add_subplot(2, 3, i+1)\n",
    "    plt.imshow(test_images[j])\n",
    "    plt.title(\"Map\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(2, 3, i+2)\n",
    "    plt.imshow(np.squeeze(test_masks[j]))\n",
    "    plt.title(\"Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    f.add_subplot(2, 3, i+3)\n",
    "    plt.imshow(np.squeeze(pred[j]))\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = normalization(np.squeeze(predictions[0][:,:,0]))\n",
    "threshold(normalized)\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observacoes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Devido ao dataset extremamente reduzido (somente 36 imagens para elaborar um esboco do projeto) e a arquitetura nada otimizada da CNN, os outputs gerados pelo modelo tem um resultado muito abaixo do esperado,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
